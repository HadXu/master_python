{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章：数据编码和处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读写CSV 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    print(headers)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headerings = next(f_csv)\n",
    "    Row = namedtuple('Row', headerings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time': '9:36am', 'Change': '-0.18', 'Symbol': 'AA', 'Price': '39.48', 'Date': '6/11/2007', 'Volume': '181800'}\n",
      "{'Time': '9:36am', 'Change': '-0.15', 'Symbol': 'AIG', 'Price': '71.38', 'Date': '6/11/2007', 'Volume': '195500'}\n",
      "{'Time': '9:36am', 'Change': '-0.46', 'Symbol': 'AXP', 'Price': '62.58', 'Date': '6/11/2007', 'Volume': '935000'}\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('stock_test.csv','wt') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果有字典，则可以这样\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "{'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "{'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('stock_dict.csv','wt') as f:\n",
    "    f_csv = csv.DictWriter(f,headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 读写JSON 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "'name' : 'ACME',\n",
    "'shares' : 100,\n",
    "'price' : 542.23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"shares\": 100, \"price\": 542.23, \"name\": \"ACME\"}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解析简单的XML 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Bengtsson: Autocompeter is Dead. Long live Autocompeter!\n",
      "Mon, 09 Jan 2017 01:14:05 +0000\n",
      "https://www.peterbe.com/plog/autocompeter-is-dead.-long-live-autocompeter\n",
      "Nikola: Nikola v7.8.2 is out!\n",
      "Sun, 08 Jan 2017 19:25:21 +0000\n",
      "https://getnikola.com/blog/nikola-v782-is-out.html\n",
      "Kushal Das: Using rkt and systemd\n",
      "Sun, 08 Jan 2017 12:01:00 +0000\n",
      "https://kushaldas.in/posts/using-rkt-and-systemd.html\n",
      "Vasudev Ram: An Unix seq-like utility in Python\n",
      "Sun, 08 Jan 2017 04:26:32 +0000\n",
      "http://jugad2.blogspot.com/2017/01/an-unix-seq-like-utility-in-python.html\n",
      "Christoph Zwerschke: Never iterate a changing dict\n",
      "Sat, 07 Jan 2017 18:52:45 +0000\n",
      "https://cito.github.io/blog/never-iterate-a-changing-dict/\n",
      "Django Weblog: 2017 DSF Board Election Results\n",
      "Sat, 07 Jan 2017 18:49:46 +0000\n",
      "https://www.djangoproject.com/weblog/2017/jan/07/2017-dsf-board-election-results/\n",
      "Programming Ideas With Jake: Default Implementations Using Delegation\n",
      "Sat, 07 Jan 2017 06:00:51 +0000\n",
      "\n",
      "Weekly Python Chat: Making your MVP\n",
      "Sat, 07 Jan 2017 00:00:00 +0000\n",
      "http://ccst.io/e/mvp\n",
      "Jason Meyers: Making the Python REPL output Pretty\n",
      "Sat, 07 Jan 2017 00:00:00 +0000\n",
      "http://jasonamyers.github.io//2017/default-to-pprint-python-repl/\n",
      "Peter Bengtsson: ElasticSearch 5 in Travis-CI\n",
      "Fri, 06 Jan 2017 22:22:02 +0000\n",
      "https://www.peterbe.com/plog/elasticsearch-5-in-travis-ci\n",
      "Weekly Python StackOverflow Report: (liv) stackoverflow python report\n",
      "Fri, 06 Jan 2017 18:27:00 +0000\n",
      "http://python-weekly.blogspot.com/2017/01/liv-stackoverflow-python-report.html\n",
      "Luke Plant: Django admin tips Twitter account\n",
      "Fri, 06 Jan 2017 16:06:55 +0000\n",
      "http://lukeplant.me.uk/blog/posts/django-admin-tips-twitter-account\n",
      "PyTennessee: PyTN Profiles: Maxwell Collins-Shenfield and Eventbrite\n",
      "Fri, 06 Jan 2017 15:20:17 +0000\n",
      "http://pytennessee.tumblr.com/post/155484120668\n",
      "Dataquest: Why You Should Use Dataquest To Learn Data Science\n",
      "Fri, 06 Jan 2017 12:00:00 +0000\n",
      "https://www.dataquest.io/blog/why-dataquest/\n",
      "Import Python: ImportPython Weekly 106 - Golang runtime for Python,  Handling Unicode Strings, Packaging and more\n",
      "Fri, 06 Jan 2017 11:09:23 +0000\n",
      "http://importpython.com/blog/post/importpython-weekly-106-golang-runtime-python-handling-unicode-strings-packaging-and-more\n",
      "Django Weekly: Django Weekly 20 - Django REST Chapter, View ORM SQL Query, Top 10 Django Projects, Testing Views\n",
      "Fri, 06 Jan 2017 10:45:43 +0000\n",
      "http://djangoweekly.com/blog/post/django-weekly-20-django-rest-chapter-view-orm-sql-query-top-10-django-projects-testing-views\n",
      "Ned Batchelder: No PyCon for me this year\n",
      "Fri, 06 Jan 2017 02:23:38 +0000\n",
      "http://nedbatchelder.com//blog/201701/no_pycon_for_me_this_year.html\n",
      "Mike Driscoll: wxPython Cookbook Artist Interview: Liza Tretyakova\n",
      "Thu, 05 Jan 2017 21:45:18 +0000\n",
      "http://www.blog.pythonlibrary.org/2017/01/05/wxpython-cookbook-artist-interview-liza-tretyakova/\n",
      "João Laia: Multiprocessing in Python via C\n",
      "Thu, 05 Jan 2017 21:39:55 +0000\n",
      "https://joao.in/blog/post/multiprocessing-python-via-c/\n",
      "Eli Bendersky: Some notes on Luz - an assembler, linker and CPU simulator\n",
      "Thu, 05 Jan 2017 14:27:00 +0000\n",
      "http://eli.thegreenplace.net/2017/some-notes-on-luz-an-assembler-linker-and-cpu-simulator/\n",
      "PyTennessee: PyTN Profiles: Brandon Wannamaker and Emma\n",
      "Thu, 05 Jan 2017 14:26:48 +0000\n",
      "http://pytennessee.tumblr.com/post/155436746663\n",
      "Corey Oordt: The road to Docker, Django and Amazon ECS, part 4\n",
      "Thu, 05 Jan 2017 13:54:20 +0000\n",
      "http://depressedoptimism.com/blog/2017/1/5/the-road-to-docker-django-and-amazon-ecs-part-4\n",
      "Yoong Kang Lim: Event sourcing in Django\n",
      "Thu, 05 Jan 2017 12:17:00 +0000\n",
      "https://yoongkang.com/blog/event-sourcing-in-django/\n",
      "Python Software Foundation: \"Weapons of Math Destruction\" by Cathy O'Neil\n",
      "Thu, 05 Jan 2017 11:34:13 +0000\n",
      "http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/6jhQTs2OTZY/weapons-of-math-destruction-by-cathy.html\n",
      "Sylvain Hellegouarch: ws4py is eager for a new maintainer\n",
      "Thu, 05 Jan 2017 09:32:07 +0000\n",
      "http://www.defuze.org/archives/409-ws4py-is-eager-for-a-new-maintainer.html\n"
     ]
    }
   ],
   "source": [
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 与关系型数据库的交互"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "你想在关系型数据库中查询、增加或删除记录。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Python 中表示多行数据的标准方式是一个由元组构成的序列。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = [\n",
    "('GOOG', 100, 490.1),\n",
    "('AAPL', 50, 545.75),\n",
    "('FB', 150, 7.45),\n",
    "('HPQ', 75, 33.2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x56495e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('create table portfolio (symbol text,share integer,price real)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x56495e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.executemany('insert into portfolio values (?,?,?)',stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 490.1)\n",
      "('AAPL', 50, 545.75)\n",
      "('FB', 150, 7.45)\n",
      "('HPQ', 75, 33.2)\n"
     ]
    }
   ],
   "source": [
    "for row in c.execute('select * from portfolio'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 编码和解码十六进制数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = b'hello'\n",
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656c6c6f'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binascii.b2a_hex(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 编码解码Base64 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = b'hello'\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.13 数据的累加与统计操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skip_footer; you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "rats = pd.read_csv('rats.csv',skip_footer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CURRENT ACTIVITY', 'Dispatch Crew', nan,\n",
       "       'Request Sanitation Inspector', 'Inspect for Violation',\n",
       "       'FVI - Outcome'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rats['Current Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = rats[rats['Current Activity']=='Dispatch Crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211237"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60618.0    12699\n",
       "60647.0    12015\n",
       "60614.0     9508\n",
       "60629.0     9067\n",
       "60657.0     8235\n",
       "60641.0     7158\n",
       "60636.0     6796\n",
       "60645.0     6518\n",
       "60609.0     6341\n",
       "60651.0     6167\n",
       "60659.0     5932\n",
       "60634.0     5801\n",
       "60632.0     5765\n",
       "60622.0     5755\n",
       "60625.0     5708\n",
       "60623.0     5407\n",
       "60620.0     5264\n",
       "60639.0     5098\n",
       "60612.0     4930\n",
       "60624.0     4728\n",
       "60613.0     4342\n",
       "60608.0     4310\n",
       "60638.0     4245\n",
       "60630.0     4234\n",
       "60621.0     3882\n",
       "60628.0     3870\n",
       "60644.0     3798\n",
       "60640.0     3613\n",
       "60619.0     3440\n",
       "60652.0     2889\n",
       "           ...  \n",
       "60660.0     2694\n",
       "60617.0     2508\n",
       "60643.0     2061\n",
       "60637.0     2057\n",
       "60610.0     2057\n",
       "60616.0     1944\n",
       "60642.0     1882\n",
       "60655.0     1636\n",
       "60615.0     1619\n",
       "60607.0     1479\n",
       "60646.0     1448\n",
       "60653.0     1332\n",
       "60649.0     1271\n",
       "60631.0     1247\n",
       "60707.0     1183\n",
       "60605.0      867\n",
       "60656.0      866\n",
       "60611.0      546\n",
       "60654.0      425\n",
       "60606.0      181\n",
       "60601.0      167\n",
       "60633.0      147\n",
       "60602.0      125\n",
       "60604.0      122\n",
       "60661.0      115\n",
       "60603.0      111\n",
       "60827.0       54\n",
       "60666.0       11\n",
       "0.0            2\n",
       "60635.0        1\n",
       "Name: ZIP Code, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['ZIP Code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas值得花一段时间来系统学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
